# Маппинги и анализаторы

Поговорим о маппингах.

Маппинг - это то, что говорит ES, как хранить некоторую информацию, индексировать её и анализировать. Это что-то вроде схемы данных. 

```json
curl -XPUT 127.0.0.1:9200/movies - d '
{
    "mappings": {
        "properties": {
            "year": {"type": "date"}
        }
    }
}
'
```

Вообще говоря, ES может сам разбирать данные по дефолтным паттернам. Например, он может определить, строка это или число. Но иногда ему нужно помочь.

В команде выше нужно было написать ещё и хедер - `-H "Content-Type: application/json"`, но можно сделать шорткат для этой команды.

Маппинги могут включать различные директивы. Наиболее частые:

- Типы полей (String, byte, short, integer, long, float, double, boolean, date);

```json
"properties": {
    "user_id": {
        "type": "long"
    }
}
```

- Индексные поля (нужно ли индексировать поле для поиска);

```json
"properties": {
    "genre": {
        "index": "not_analyzed"
    }
}
```

- Анализаторы (токенизаторы и токен-фильтры);

```json
"properties": {
    "description": {
        "analyzer": "english"
    }
}
```

## Анализаторы

Анализаторы могут делать разное. Например, там могут быть фильтры символов. Через них можно заменить амперсанды на "И", убрать теги HTML и прочее.

Можно делать **токенизацию** через токенизаторы. Это то, как следует разбивать строки на отдельные слова и фразы базируясь на пробелах или знаках препинания. 

Токен-фильтры позволяют приводить текст к нижнему регистру, выявлять синонимы отсеивать и стоп-слова. Есть несколько стандартных токенизаторов. Один разбивает слова по символам, которые не являются буквами и приводит текст к нижнему регистру. Другой просто приводит к нижнему регистру.

Можно указать язык индекса. Для разных языков могут быть разные правила синонимов и стоп-слов.

Итак, **анализатор может**:

- Фильтровать символы (убрать тэги HTML, конвертировать & в И и т.п.);
- Токенизировать (разбиение строк на слова и фразы по делителям);
- Фильтровать токены (приведение к нижнему регистру, определение разных форм одного слова, определение синонимов, стоп-слов).

Важно тут то, что **анализаторы применяются как к данным в индексе, так и к поиску в индексе**. Это значит, что если анализатор меняет & на "И" для данных в индексе, то при поиске можно искать и то и другое. 

Стоп-слова - это слова, которые можно не хранить. Это могут быть предлоги и всё в таком духе. Например, "и", "the", "and"... При поиске фраз имеет смысл эти слова сохранять. Например, фраза "to be or not to be" может вообще целиком оказаться отброшенной таким фильтром.

### Виды анализаторов

- Standard - разделение на слова, убирает пунктуацию, приводит к нижнему регистру. Подходит когда неизвестно, какой язык будет в индексе;
- Simple - разделение по символам, которые не являются буквами, приведение к нижнему регистру;
- Whitespace - разделение по пробелам;
- Language - описывает специфичные для языка стоп-слова и правила нахождения разных форм слов.

Можно совмещать разные языки в одном языке, можно даже хранить один и тот же текст, проанализированный разными анализаторами, в разных полях. 











